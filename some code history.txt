# intelligent_robot_controller.py
# Intelligent Robot Project Controller Skeleton (Version: Stable Obstacle Avoidance + Debounce + Improved Unstuck Logic)

from controller import Supervisor
import math

TIME_STEP = 64  # Simulation time step (must match world basicTimeStep)

# !!! Change this to the robot’s initial translation (x, y) as seen in the world !!!
START_X = -3.0
START_Y = -3.0

# !!! Change this to the goal’s (x, y) in the world !!!
GOAL_POSITION = (1.0, 1.0)
CHARGING_STATION = (3.0, -3.0)

# Consider reaching the goal when within 15 cm
GOAL_REACHED_DIST = 0.15


# =====================================================================
# I. Robot State Class (RobotState)
# =====================================================================

class RobotState:
    def __init__(self):
        # Battery system
        self.battery_level = 100.0
        
        # Obstacle-related
        self.min_obstacle_distance = 1.0
        self.obstacle_danger = 0.0

        # Left/right obstacle intensity
        self.left_obstacle = 0.0
        self.right_obstacle = 0.0
        
        # Robot pose (world coordinates, plane is x–y, z ignored)
        self.x = START_X     # World coordinate x
        self.y = START_Y     # World coordinate y
        self.theta = 0.0     # Heading angle (radians), 0 approx. +x direction
        
        self.going_to_charging = False
        
        # Goal-related
        self.distance_to_goal = 0.0
        self.heading_error = 0.0   # Robot heading minus “target direction” (-π~π)
        self.goal_visible = 1.0
        
        # Path deviation level
        self.path_deviation = 0.0
        
        # Stuck indicator (for potential stuck detection)
        self.stuck_indicator = 0.0


# =====================================================================
# II. Behavior Base Class (Behavior)
# =====================================================================

class Behavior:
    """Parent class for all behaviors"""
    def __init__(self, name):
        self.name = name
    
    def compute_activation(self, state: RobotState):
        return 0.0
    
    def execute(self, state: RobotState):
        return 0.0, 0.0


# =====================================================================
# III. Basic Behaviors (Obstacle Avoidance, Navigation, Emergency Unstuck)
# =====================================================================

class AvoidObstacleBehavior(Behavior):
    def __init__(self):
        super().__init__("AvoidObstacle")
    
    def compute_activation(self, state: RobotState):
        # When goal reached, fully disable obstacle avoidance
        if state.distance_to_goal < GOAL_REACHED_DIST:
            return 0.0
        # Higher danger → higher priority
        return state.obstacle_danger

    def execute(self, state: RobotState):
        d = state.obstacle_danger

        # Very close — force fast straight backward (easier to trigger than before)
        if d > 0.7:
            return -5.0, -5.0

        # Medium danger: move backward while turning
        left = state.left_obstacle
        right = state.right_obstacle

        # More obstacles on the left → back up to the right
        if left > right + 0.05:
            return -2.0, -4.0

        # More obstacles on the right → back up to the left
        if right > left + 0.05:
            return -4.0, -2.0

        # Similar on both sides → rotate in place to find a new direction
        return -2.5, 2.5


class NavigateBehavior(Behavior):
    def __init__(self):
        super().__init__("NavigateToGoal")
    
    def compute_activation(self, state: RobotState):
        if state.distance_to_goal < GOAL_REACHED_DIST:
            return 0.0
        base = 1.0 - state.obstacle_danger
        if state.distance_to_goal < 0.3:
            base *= 0.5
        return max(0.0, min(1.0, base))

    def execute(self, state: RobotState):
        # 1) If near the goal → stop
        if state.distance_to_goal < GOAL_REACHED_DIST:
            print("[NAV] Goal reached, stopping.")
            return 0.0, 0.0

        # 2) Base forward speed
        base_speed = 4.0

        # 3) Compute turning term w, make it “not too large”
        k_turn = 2.0              # Much smaller than previous 5.0, less aggressive
        w = k_turn * state.heading_error

        # Limit w to ensure |w| < base_speed
        w_max = 3.0               # 3 < base_speed=4, ensures positive forward motion
        if w > w_max:
            w = w_max
        elif w < -w_max:
            w = -w_max

        # 4) Compute wheel speeds (always positive)
        left = base_speed - w
        right = base_speed + w

        # 5) Limit max wheel speed
        max_speed = 6.28
        left = max(-max_speed, min(max_speed, left))
        right = max(-max_speed, min(max_speed, right))

        # 6) Slow down if close to goal
        if state.distance_to_goal < 0.3:
            left *= 0.5
            right *= 0.5

        print(f"[CMD] NavigateToGoal -> vL={left:.2f}, vR={right:.2f}")
        return left, right


class EmergencyStopBehavior(Behavior):
    """
    Improved emergency unstuck behavior:
    - phase 1: Strong backward motion
    - phase 2: In-place turning (pseudo-random direction)
    - phase 3: Low-speed forward push
    - phase 4: Pause for one frame, then check danger again to decide whether to retry or exit
    """
    def __init__(self):
        super().__init__("EmergencyStop")

        self.phase = 0          # 0 not started, 1 backward, 2 turn, 3 forward, 4 wait
        self.step  = 0
        self.turn_dir = 1       # +1 left, -1 right

    def compute_activation(self, state: RobotState):
        # If goal reached, do not trigger emergency unstuck
        if state.distance_to_goal < GOAL_REACHED_DIST:
            self.phase = 0
            self.step = 0
            return 0.0

        # If already executing unstuck sequence → stay active
        if self.phase > 0:
            return 1.0

        # Trigger unstuck only under high danger (threshold lowered from 0.95 to 0.7)
        if state.obstacle_danger > 0.7:
            self.phase = 1
            self.step = 0
            # Simple pseudo-random turn direction using parity of position
            self.turn_dir = 1 if (state.x + state.y) % 2.0 < 1.0 else -1
            print("[EST] START back-off")
            return 1.0

        return 0.0

    def execute(self, state: RobotState):
        # Phase not started
        if self.phase == 0:
            return 0.0, 0.0

        # 1) Backward for 60 steps
        if self.phase == 1:
            if self.step < 60:
                self.step += 1
                return -6.0, -6.0
            else:
                self.phase = 2
                self.step = 0
                print("[EST] START turn")

        # 2) In-place turning for 50 steps (random direction)
        if self.phase == 2:
            if self.step < 50:
                self.step += 1
                return -4.0 * self.turn_dir, 4.0 * self.turn_dir
            else:
                self.phase = 3
                self.step = 0
                print("[EST] START escape")

        # 3) Low-speed forward push for 30 steps
        if self.phase == 3:
            if self.step < 30:
                self.step += 1
                return 3.0, 3.0
            else:
                self.phase = 4          # Pause to update sensors
                self.step = 0
                print("[EST] WAIT sensor")

        # 4) Pause: retry if danger still high, otherwise exit
        if self.phase == 4:
            if state.obstacle_danger > 0.7:
                self.phase = 1          # Retry cycle
                self.step  = 0
                print("[EST] RETRY")
            else:
                self.phase = 0          # Danger gone, exit normally
        return 0.0, 0.0


# =====================================================================
# Fuzzy decision (not used yet, placeholder only)
# =====================================================================

class FuzzyDecision:
    def __init__(self):
        pass

    def danger_low(self, x: float) -> float:
        if x <= 0.3:
            return 1.0
        elif x >= 0.5:
            return 0.0
        else:
            return (0.5 - x) / (0.5 - 0.3)

    def danger_medium(self, x: float) -> float:
        if x <= 0.2 or x >= 0.8:
            return 0.0
        elif x <= 0.5:
            return (x - 0.2) / (0.5 - 0.2)
        else:
            return (0.8 - x) / (0.8 - 0.5)

    def danger_high(self, x: float) -> float:
        if x <= 0.6:
            return 0.0
        elif x >= 0.8:
            return 1.0
        else:
            return (x - 0.6) / (0.8 - 0.6)

    def get_activations(self, state: RobotState):
        d = state.obstacle_danger

        mu_low = self.danger_low(d)
        mu_med = self.danger_medium(d)
        mu_high = self.danger_high(d)

        navigate = 0.0
        avoid = 0.0
        stop = 0.0

        # Low
        navigate = max(navigate, mu_low * 1.0)
        avoid    = max(avoid,    mu_low * 0.1)
        stop     = max(stop,     mu_low * 0.0)

        # Medium
        navigate = max(navigate, mu_med * 0.5)
        avoid    = max(avoid,    mu_med * 1.0)
        stop     = max(stop,     mu_med * 0.2)

        # High
        navigate = max(navigate, mu_high * 0.1)
        avoid    = max(avoid,    mu_high * 0.5)
        stop     = max(stop,     mu_high * 1.0)

        navigate = min(1.0, navigate)
        avoid    = min(1.0, avoid)
        stop     = min(1.0, stop)

        return {
            "NavigateToGoal": navigate,
            "AvoidObstacle": avoid,
            "EmergencyStop": stop
        }


# =====================================================================
# IV. Behavior Tree — with Hysteresis and Minimum Dwell Time
# =====================================================================

class BehaviorTree:
    def __init__(self, behaviors, fuzzy_decision=None):
        self.behaviors = behaviors
        self.fuzzy = fuzzy_decision

        self.current_behavior = None
        self.last_switch_tick = 0

    def decide(self, state: RobotState, tick: int):
        # Currently not using fuzzy logic; directly use each behavior’s compute_activation,
        # but add “hysteresis + minimum dwell time” to suppress oscillation.
        if self.fuzzy is None:
            activations = {}
            for b in self.behaviors:
                activations[b] = b.compute_activation(state)

            # Initial selection
            if self.current_behavior is None:
                best_behavior = max(activations, key=activations.get)
                self.current_behavior = best_behavior
                self.last_switch_tick = tick
                print(f"[BT] Init -> {best_behavior.name} (a={activations[best_behavior]:.2f}, tick={tick})")
                return self.current_behavior

            # Current behavior and best behavior
            best_behavior = max(activations, key=activations.get)
            a_best = activations[best_behavior]
            a_curr = activations[self.current_behavior]

            # ===== Oscillation suppression parameters =====
            MIN_DWELL = 15   # A behavior must last at least 15 ticks
            HYST = 0.15      # New behavior must exceed current by 0.15 to switch

            chosen = self.current_behavior

            # If current behavior hasn’t lasted long enough → keep it
            if tick - self.last_switch_tick < MIN_DWELL:
                chosen = self.current_behavior
            else:
                # Enough time has passed; switch if clearly better
                if a_best > a_curr + HYST:
                    chosen = best_behavior

            if chosen is not self.current_behavior:
                print(f"[BT] Switch {self.current_behavior.name} -> {chosen.name} "
                      f"(a_curr={a_curr:.2f}, a_best={a_best:.2f}, tick={tick})")
                self.current_behavior = chosen
                self.last_switch_tick = tick

            return self.current_behavior

        # Fuzzy-logic branch (currently unused)
        activations = self.fuzzy.get_activations(state)
        best_name = max(activations, key=activations.get)
        best_activation = activations[best_name]

        best_behavior = None
        for b in self.behaviors:
            if b.name == best_name:
                best_behavior = b
                break

        if best_behavior is None:
            return None

        if self.current_behavior is None or best_behavior is not self.current_behavior:
            self.current_behavior = best_behavior
            self.last_switch_tick = tick
            print(f"[BT-FUZZY] Switch to {best_behavior.name} (a={best_activation:.2f}, tick={tick})")

        return self.current_behavior


# =====================================================================
# V. Main Controller: Webots Interface
# =====================================================================

class IntelligentRobotController(Supervisor):
    def __init__(self):
        super().__init__()
        
        # Store robot node to read world coordinates
        self.robot_node = self.getSelf()

        # ------------- Motor initialization -------------
        self.left_motor = self.getMotor("left wheel motor")
        self.right_motor = self.getMotor("right wheel motor")

        self.left_motor.setPosition(float('inf'))
        self.right_motor.setPosition(float('inf'))
        
        self.left_motor.setVelocity(0.0)
        self.right_motor.setVelocity(0.0)
        
        # ------------- Distance sensors -------------
        self.distance_sensors = []
        sensor_names = ["ps0", "ps1", "ps2", "ps3", "ps4", "ps5", "ps6", "ps7"]
        for name in sensor_names:
            sensor = self.getDevice(name)
            if sensor is not None:
                sensor.enable(TIME_STEP)
                self.distance_sensors.append(sensor)
        
        # Robot state
        self.state = RobotState()
        
        # Behavior tree: priority high → low (EmergencyStop dominates once triggered)
        self.behaviors = [
            EmergencyStopBehavior(),
            AvoidObstacleBehavior(),
            NavigateBehavior()
        ]
        self.fuzzy_decision = None

        self.bt = BehaviorTree(self.behaviors, self.fuzzy_decision)

        # Tick counter
        self.tick = 0

    def update_battery_and_target(self, moving: bool):
        """
        Simple battery model:
        - Battery drains faster when moving
        - Drains slowly when idle
        - Low battery → switch target to charging station
        - When near charging station, recharge slowly; when full, return to main goal
        """
        # 1) Battery consumption
        if moving:
            self.state.battery_level -= 0.03    # Moving drains 0.03 per step
        else:
            self.state.battery_level -= 0.005   # Idle drains a small amount

        # Clamp to [0, 100]
        if self.state.battery_level < 0.0:
            self.state.battery_level = 0.0
        if self.state.battery_level > 100.0:
            self.state.battery_level = 100.0

        # 2) Low battery → go to charging station
        if (not self.state.going_to_charging) and self.state.battery_level < 30.0:
            self.state.going_to_charging = True
            print(">>> [BAT] Low battery, switch target to CHARGING STATION")

        # 3) When near charging station, start charging
        if self.state.going_to_charging and self.state.distance_to_goal < GOAL_REACHED_DIST:
            # Simple recharge model: +0.5 per step
            self.state.battery_level += 0.5
            if self.state.battery_level >= 99.0:
                self.state.battery_level = 100.0
                self.state.going_to_charging = False
                print(">>> [BAT] Fully charged, switch target back to GOAL")
    

    def update_odometry(self):
        # 1. Read actual position from world
        trans = self.robot_node.getField("translation").getSFVec3f()
        self.state.x = trans[0]   # planar x
        self.state.y = trans[1]   # planar y
    
        # 2. Real orientation (assume rotation only around z axis)
        rot = self.robot_node.getField("rotation").getSFRotation()
        axis_x, axis_y, axis_z, angle = rot
        self.state.theta = angle
    
        # 3. Compute distance and direction to “current target”
        if self.state.going_to_charging:
            goal_x, goal_y = CHARGING_STATION
            target_name = "CHARGING"
        else:
            goal_x, goal_y = GOAL_POSITION
            target_name = "GOAL"
    
        dx = goal_x - self.state.x
        dy = goal_y - self.state.y
    
        distance = math.sqrt(dx * dx + dy * dy)
        self.state.distance_to_goal = distance
    
        target_theta = math.atan2(dy, dx)
        heading_err = target_theta - self.state.theta
        heading_err = (heading_err + math.pi) % (2 * math.pi) - math.pi
        self.state.heading_error = heading_err
    
        print(
            f"Pose(gt): x={self.state.x:.2f}, y={self.state.y:.2f}, "
            f"theta={self.state.theta:.2f}, dist={distance:.2f}, "
            f"target={target_name}, battery={self.state.battery_level:.1f}, "
            f"heading_err={heading_err:.2f}"
        )

        
    # =================================================================
# Update state (IMPORTANT)
# =================================================================

def update_state_from_sensors(self):
    if not self.distance_sensors:
        print("No distance sensors found!")
        return

    values = [s.getValue() for s in self.distance_sensors]
    max_val = max(values)

    print("Sensor values:", [int(v) for v in values], " max:", int(max_val))

    # Rough sensor baseline and normalization
    baseline = 60.0
    max_range = 80.0

    danger_raw = (max_val - baseline) / max_range
    danger = max(0.0, min(1.0, danger_raw))

    self.state.obstacle_danger = danger
    self.state.min_obstacle_distance = 1.0 - danger

    # Estimate left/right obstacle intensity
    if len(values) == 8:
        left_sum = values[0] + values[1] + values[2] + values[3]
        right_sum = values[4] + values[5] + values[6] + values[7]
    else:
        mid = len(values) // 2
        left_sum = sum(values[:mid])
        right_sum = sum(values[mid:])

    norm_factor = 400.0
    self.state.left_obstacle = min(1.0, left_sum / norm_factor)
    self.state.right_obstacle = min(1.0, right_sum / norm_factor)

    print(
        "Obstacle danger:", round(danger, 3),
        " | left:", round(self.state.left_obstacle, 3),
        " right:", round(self.state.right_obstacle, 3)
    )

# =================================================================
# Main program loop
# =================================================================
def run_controller(self):
    # Previous control command (used to detect whether robot is moving)
    last_left = 0.0
    last_right = 0.0

    while self.step(TIME_STEP) != -1:
        self.tick += 1

        # 0. Odometry: update pose & relation to target
        self.update_odometry()

        # 1. Sensor update
        self.update_state_from_sensors()
        
        # 2. Behavior tree decision
        behavior = self.bt.decide(self.state, self.tick)
        
        # 3. Execute behavior
        if behavior is None:
            left_speed, right_speed = 0.0, 0.0
        else:
            left_speed, right_speed = behavior.execute(self.state)
        
        # 4. Battery + task switching (based on whether robot is moving)
        moving = (abs(left_speed) > 0.1 or abs(right_speed) > 0.1)
        self.update_battery_and_target(moving)

        # 5. Set wheel speeds
        self.left_motor.setVelocity(left_speed)
        self.right_motor.setVelocity(right_speed)

        # Optional log (for future “stuck detection”)
        last_left = left_speed
        last_right = right_speed


# =====================================================================
# Six.Entrance
# =====================================================================

if __name__ == "__main__":
    controller = IntelligentRobotController()
    controller.run_controller()
-----------------------------------------------------------1111111111111111111111------------------------------------------------------------

# intelligent_robot_controller.py
# Simplified stable version:
# Straightforward navigation + simple obstacle avoidance + battery management + auto charging
# Behavior tree / fuzzy system removed for easier debugging and understanding

from controller import Supervisor
import math

TIME_STEP = 64  # Must match basicTimeStep in the world file

# ======= Setup based on your screenshot =======
# Robot:  position -3 -3 0.00017
# Goal:   position  1  1 2.69
# Charge: position  3 -3 0.3
START_X = -3.0
START_Y = -3.0

GOAL_POSITION = (1.0, 1.0)
CHARGING_STATION = (3.0, -3.0)

GOAL_REACHED_DIST = 0.15   # Goal considered reached within 15 cm


class RobotState:
    def __init__(self):
        self.x = START_X
        self.y = START_Y
        self.theta = 0.0

        self.battery_level = 100.0

        self.going_to_charging = False
        self.distance_to_goal = 0.0
        self.heading_error = 0.0

        self.obstacle_danger = 0.0
        self.left_obstacle = 0.0
        self.right_obstacle = 0.0

        self.mission_done = False


class IntelligentRobotController(Supervisor):
    def __init__(self):
        super().__init__()

        self.robot_node = self.getSelf()

        # Motors
        self.left_motor = self.getDevice("left wheel motor")
        self.right_motor = self.getDevice("right wheel motor")

        self.left_motor.setPosition(float('inf'))
        self.right_motor.setPosition(float('inf'))

        self.left_motor.setVelocity(0.0)
        self.right_motor.setVelocity(0.0)

        # Distance sensors
        sensor_names = ["ps0", "ps1", "ps2", "ps3", "ps4", "ps5", "ps6", "ps7"]
        self.distance_sensors = []
        for name in sensor_names:
            s = self.getDevice(name)
            if s is not None:
                s.enable(TIME_STEP)
                self.distance_sensors.append(s)

        self.state = RobotState()
        self.tick = 0

    # ========== Pose update ==========
    def update_pose(self):
        trans = self.robot_node.getField("translation").getSFVec3f()
        rot = self.robot_node.getField("rotation").getSFRotation()

        # In this world, the ground plane is x-y, and z is height
        self.state.x = trans[0]
        self.state.y = trans[1]

        axis_x, axis_y, axis_z, angle = rot
        # The rotation axis is basically (0,0,1); angle is the heading
        self.state.theta = angle

        # Select the current target point
        if self.state.going_to_charging:
            gx, gy = CHARGING_STATION
            target_name = "CHARGE"
        else:
            gx, gy = GOAL_POSITION
            target_name = "GOAL"

        dx = gx - self.state.x
        dy = gy - self.state.y
        dist = math.hypot(dx, dy)
        self.state.distance_to_goal = dist

        target_theta = math.atan2(dy, dx)
        heading_err = target_theta - self.state.theta
        heading_err = (heading_err + math.pi) % (2.0 * math.pi) - math.pi
        self.state.heading_error = heading_err

        # Final goal achieved
        if (not self.state.going_to_charging) and dist < GOAL_REACHED_DIST:
            if not self.state.mission_done:
                print(">>> [TASK] Final goal reached, mission done.")
            self.state.mission_done = True

        return target_name

    # ========== Sensors ==========
    def update_sensors(self):
        if not self.distance_sensors:
            return

        values = [s.getValue() for s in self.distance_sensors]
        max_val = max(values)

        # Sensor values are around 60–80; larger means closer
        baseline = 60.0
        max_range = 80.0
        danger_raw = (max_val - baseline) / max_range
        danger = max(0.0, min(1.0, danger_raw))
        self.state.obstacle_danger = danger

        # Sum the left/right 4 sensors
        if len(values) == 8:
            left_sum = sum(values[0:4])
            right_sum = sum(values[4:8])
        else:
            mid = len(values) // 2
            left_sum = sum(values[:mid])
            right_sum = sum(values[mid:])

        norm = 400.0
        self.state.left_obstacle = min(1.0, left_sum / norm)
        self.state.right_obstacle = min(1.0, right_sum / norm)

    # ========== Battery & target switching ==========
    def update_battery_and_target(self, moving: bool):
        if self.state.mission_done:
            return

        # Very simple battery model
        if moving:
            self.state.battery_level -= 0.03
        else:
            self.state.battery_level -= 0.005

        if self.state.battery_level < 0.0:
            self.state.battery_level = 0.0
        if self.state.battery_level > 100.0:
            self.state.battery_level = 100.0

        # Low battery → switch to charging station
        if (not self.state.going_to_charging) and self.state.battery_level < 30.0:
            self.state.going_to_charging = True
            print(">>> [BAT] Low battery, go to CHARGING_STATION")

        # Near charging station → slow charging
        if self.state.going_to_charging and self.state.distance_to_goal < GOAL_REACHED_DIST:
            self.state.battery_level += 0.5
            if self.state.battery_level >= 100.0:
                self.state.battery_level = 100.0
                self.state.going_to_charging = False
                print(">>> [BAT] Fully charged, switch back to GOAL")

    # ========== Compute velocity command ==========
    def compute_command(self):
        if self.state.mission_done or self.state.battery_level <= 0.0:
            return 0.0, 0.0

        d = self.state.distance_to_goal
        e = self.state.heading_error
        danger = self.state.obstacle_danger
        left_o = self.state.left_obstacle
        right_o = self.state.right_obstacle

        # Basic idea:
        # 1. Very high danger: force reverse + turn away from obstacle
        # 2. Medium danger: slow down + side-steer around obstacle
        # 3. Low danger: navigate toward target based on heading error

        max_speed = 6.28

        # 1) High danger → emergency backward
        if danger > 0.7:
            turn_bias = 2.0 if left_o > right_o else -2.0
            v = -3.0
            w = turn_bias
        # 2) Medium danger → slow down & steer based on sensor difference
        elif danger > 0.3:
            v = 2.0
            w = 3.0 * (right_o - left_o)    # If left side is closer → turn right
        else:
            # 3) Normal navigation: P-control
            v = 4.0 * min(d, 1.0)
            w = 3.0 * e

        # Convert (v, w) to wheel speeds
        v_left = v - w
        v_right = v + w

        # Limit motor speed range
        v_left = max(-max_speed, min(max_speed, v_left))
        v_right = max(-max_speed, min(max_speed, v_right))

        return v_left, v_right

    # ========== Main loop ==========
    def run_controller(self):
        last_log_tick = -999

        while self.step(TIME_STEP) != -1:
            self.tick += 1

            if self.state.battery_level <= 0.0:
                print(">>> [BAT] Battery empty, stop.")
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            if self.state.mission_done:
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            target_name = self.update_pose()
            self.update_sensors()

            v_left, v_right = self.compute_command()

            moving = (abs(v_left) > 0.05 or abs(v_right) > 0.05)
            self.update_battery_and_target(moving)

            self.left_motor.setVelocity(v_left)
            self.right_motor.setVelocity(v_right)

            # Log every 20 ticks to avoid spamming
            if self.tick - last_log_tick >= 20:
                last_log_tick = self.tick
                print(
                    f"[t={self.tick}] pos=({self.state.x:.2f},{self.state.y:.2f}) "
                    f"theta={self.state.theta:.2f} "
                    f"target={target_name} dist={self.state.distance_to_goal:.2f} "
                    f"batt={self.state.battery_level:.1f} "
                    f"danger={self.state.obstacle_danger:.2f} "
                    f"Lobs={self.state.left_obstacle:.2f} "
                    f"Robs={self.state.right_obstacle:.2f} "
                    f"cmd=({v_left:.2f},{v_right:.2f})"
                )


if __name__ == "__main__":
    controller = IntelligentRobotController()
    controller.run_controller()

-----------------------22222222222222222222 Fuzzy Behavior Selection + Jitter Suppression Framework code--------------------------------------

# intelligent_robot_controller.py
# Upgraded version: adds
# 1) Fuzzy behavior activation (GOAL / AVOID / CHARGE)
# 2) Behavior selection + jitter suppression (hysteresis + cooldown)
# 3) Charging-station parking logic

from controller import Supervisor
import math

TIME_STEP = 64  # Must match basicTimeStep in the world

# ======= Scene Settings =======
START_X = -3.0
START_Y = -3.0

GOAL_POSITION = (1.0, 1.0)
CHARGING_STATION = (3.0, -3.0)

GOAL_REACHED_DIST = 0.15        # Consider goal reached if within 15 cm
CHARGING_REACHED_DIST = 0.15    # Charging-station radius


class RobotState:
    def __init__(self):
        self.x = START_X
        self.y = START_Y
        self.theta = 0.0

        # Battery
        self.battery_level = 100.0

        # Goal & navigation
        self.going_to_charging = False
        self.distance_to_goal = 0.0
        self.heading_error = 0.0

        # Obstacle-related
        self.obstacle_danger = 0.0
        self.left_obstacle = 0.0
        self.right_obstacle = 0.0

        # Behavior-selection
        self.active_behavior = "GOAL"   # "GOAL" / "AVOID" / "CHARGE"
        self.last_behavior = "GOAL"
        self.last_switch_tick = 0

        self.mission_done = False


class IntelligentRobotController(Supervisor):
    def __init__(self):
        super().__init__()

        self.robot_node = self.getSelf()

        # Motors
        self.left_motor = self.getDevice("left wheel motor")
        self.right_motor = self.getDevice("right wheel motor")

        self.left_motor.setPosition(float('inf'))
        self.right_motor.setPosition(float('inf'))
        self.left_motor.setVelocity(0.0)
        self.right_motor.setVelocity(0.0)

        # Distance sensors
        sensor_names = ["ps0", "ps1", "ps2", "ps3", "ps4", "ps5", "ps6", "ps7"]
        self.distance_sensors = []
        for name in sensor_names:
            s = self.getDevice(name)
            if s is not None:
                s.enable(TIME_STEP)
                self.distance_sensors.append(s)

        self.state = RobotState()
        self.tick = 0

        # Behavior selection parameters
        self.behavior_cooldown = 20     # Cannot switch behavior for at least 20 ticks
        self.hysteresis_margin = 0.1    # Maintain behavior if activation is within 0.1 of max

    # ========== Pose Update ==========
    def update_pose(self):
        trans = self.robot_node.getField("translation").getSFVec3f()
        rot = self.robot_node.getField("rotation").getSFRotation()

        # In this world, the ground plane is x–y, z is height
        self.state.x = trans[0]
        self.state.y = trans[1]

        axis_x, axis_y, axis_z, angle = rot
        # Assume axis is mainly z-axis, angle is heading
        self.state.theta = angle

        # Choose navigation target (GOAL or CHARGE)
        if self.state.active_behavior == "CHARGE":
            gx, gy = CHARGING_STATION
            target_name = "CHARGE"
        else:
            gx, gy = GOAL_POSITION
            target_name = "GOAL"

        dx = gx - self.state.x
        dy = gy - self.state.y
        dist = math.hypot(dx, dy)
        self.state.distance_to_goal = dist

        target_theta = math.atan2(dy, dx)
        heading_err = target_theta - self.state.theta
        heading_err = (heading_err + math.pi) % (2.0 * math.pi) - math.pi
        self.state.heading_error = heading_err

        # Final goal reached (only if behavior is GOAL)
        if (self.state.active_behavior != "CHARGE") and dist < GOAL_REACHED_DIST:
            if not self.state.mission_done:
                print(">>> [TASK] Final goal reached, mission done.")
            self.state.mission_done = True

        return target_name

    # ========== Sensors ==========
    def update_sensors(self):
        if not self.distance_sensors:
            return

        values = [s.getValue() for s in self.distance_sensors]
        max_val = max(values)

        # Typical values ~60–80: larger = closer
        # You may adjust baseline/max_range later
        baseline = 60.0
        max_range = 80.0
        danger_raw = (max_val - baseline) / max_range
        danger = max(0.0, min(1.0, danger_raw))
        self.state.obstacle_danger = danger

        # Sum left/right 4 sensors (ps0-3 left, ps4-7 right)
        if len(values) == 8:
            left_sum = sum(values[0:4])
            right_sum = sum(values[4:8])
        else:
            mid = len(values) // 2
            left_sum = sum(values[:mid])
            right_sum = sum(values[mid:])

        norm = 400.0
        self.state.left_obstacle = min(1.0, left_sum / norm)
        self.state.right_obstacle = min(1.0, right_sum / norm)

    # ========== Battery Update (no direct behavior switching here) ==========
    def update_battery(self, moving: bool):
        if self.state.mission_done:
            return

        # Simple battery model
        if moving:
            self.state.battery_level -= 0.03
        else:
            self.state.battery_level -= 0.005

        if self.state.battery_level < 0.0:
            self.state.battery_level = 0.0
        if self.state.battery_level > 100.0:
            self.state.battery_level = 100.0

        # If in charging zone and behavior is CHARGE → charge & stop
        if self.state.active_behavior == "CHARGE":
            dist_to_charge = math.hypot(
                self.state.x - CHARGING_STATION[0],
                self.state.y - CHARGING_STATION[1]
            )
            if dist_to_charge < CHARGING_REACHED_DIST:
                # Charging is achieved by send speed = 0 in run_loop
                self.state.battery_level += 0.5
                if self.state.battery_level >= 100.0:
                    self.state.battery_level = 100.0
                    # When full, the next behavior-selection cycle may return to GOAL
                    print(">>> [BAT] Fully charged at station.")

    # ========== Fuzzy Membership Functions ==========
    def fuzzy_low_battery(self, batt: float) -> float:
        """
        Battery fuzzy set: low
        >= 60 → 0, <= 20 → 1, linear in between
        """
        if batt >= 60.0:
            return 0.0
        if batt <= 20.0:
            return 1.0
        return (60.0 - batt) / 40.0

    def fuzzy_obstacle_near(self, danger: float) -> float:
        """
        Obstacle proximity: directly uses danger (clamped)
        """
        return max(0.0, min(1.0, danger))

    def fuzzy_far_from_goal(self, dist: float) -> float:
        """
        Far-from-goal: larger distance → larger activation (0~1 m normalized)
        """
        if dist <= 0.1:
            return 0.0
        if dist >= 1.0:
            return 1.0
        return (dist - 0.1) / 0.9

    # ========== Behavior Selection (fuzzy + hysteresis + cooldown) ==========
    def select_behavior(self):
        batt = self.state.battery_level
        danger = self.state.obstacle_danger
        dist = self.state.distance_to_goal

        mu_low_batt = self.fuzzy_low_battery(batt)
        mu_obs = self.fuzzy_obstacle_near(danger)
        mu_far = self.fuzzy_far_from_goal(dist)

        # Basic activation design (you may upgrade later)
        act_charge = mu_low_batt               # Lower battery → stronger CHARGE
        act_avoid = mu_obs                     # Closer obstacle → stronger AVOID
        act_goal = (1.0 - mu_low_batt) * max(0.0, 1.0 - mu_obs) * mu_far

        activations = {
            "CHARGE": act_charge,
            "AVOID": act_avoid,
            "GOAL": act_goal
        }

        # Find behavior with maximum activation
        best_behavior = max(activations, key=activations.get)
        best_act = activations[best_behavior]

        current = self.state.active_behavior
        current_act = activations[current]

        # Jitter suppression 1: Cooldown period
        if (self.tick - self.state.last_switch_tick) < self.behavior_cooldown:
            # Only switch if new behavior clearly stronger
            if best_act > current_act + self.hysteresis_margin:
                self.state.last_behavior = current
                self.state.active_behavior = best_behavior
                self.state.last_switch_tick = self.tick
        else:
            # Outside cooldown: only switch if significantly stronger
            if current_act + self.hysteresis_margin < best_act:
                self.state.last_behavior = current
                self.state.active_behavior = best_behavior
                self.state.last_switch_tick = self.tick

        # active_behavior decides whether we are heading to charging station
        self.state.going_to_charging = (self.state.active_behavior == "CHARGE")

        return activations

    # ========== Compute Wheel Commands ==========
    def compute_command(self):
        if self.state.mission_done or self.state.battery_level <= 0.0:
            return 0.0, 0.0

        d = self.state.distance_to_goal
        e = self.state.heading_error
        danger = self.state.obstacle_danger
        left_o = self.state.left_obstacle
        right_o = self.state.right_obstacle

        max_speed = 6.28

        behavior = self.state.active_behavior

        # If in CHARGE mode and inside charging radius → stop completely
        if behavior == "CHARGE":
            dist_to_charge = math.hypot(
                self.state.x - CHARGING_STATION[0],
                self.state.y - CHARGING_STATION[1]
            )
            if dist_to_charge < CHARGING_REACHED_DIST:
                return 0.0, 0.0

        # Behavior-specific control
        if behavior == "AVOID":
            # Slightly more aggressive obstacle avoidance
            if danger > 0.6:
                # High danger: reverse + strong turn
                turn_bias = 3.0 if left_o > right_o else -3.0
                v = -2.5
                w = turn_bias
            else:
                # Medium danger: slow forward + side steering
                v = 1.5
                w = 4.0 * (right_o - left_o)

        elif behavior == "CHARGE":
            # Move to charging station (like GOAL but more conservative)
            v = 3.0 * min(d, 1.0)
            w = 3.0 * e

        else:  # "GOAL"
            # Normal navigation
            if danger > 0.5:
                # Even in GOAL mode, avoid moderately if danger present
                v = 2.0
                w = 3.0 * (right_o - left_o)
            else:
                v = 4.0 * min(d, 1.0)
                w = 3.0 * e

        v_left = v - w
        v_right = v + w

        v_left = max(-max_speed, min(max_speed, v_left))
        v_right = max(-max_speed, min(max_speed, v_right))

        return v_left, v_right

    # ========== Main Loop ==========
    def run_controller(self):
        last_log_tick = -999

        while self.step(TIME_STEP) != -1:
            self.tick += 1

            if self.state.battery_level <= 0.0:
                print(">>> [BAT] Battery empty, stop.")
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            if self.state.mission_done:
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            # Pose & sensor update
            target_name = self.update_pose()
            self.update_sensors()

            # Behavior selection (fuzzy + jitter suppression)
            acts = self.select_behavior()

            # Compute wheel speeds
            v_left, v_right = self.compute_command()

            moving = (abs(v_left) > 0.05 or abs(v_right) > 0.05)

            # Update battery (includes charging logic)
            self.update_battery(moving)

            # Send commands
            self.left_motor.setVelocity(v_left)
            self.right_motor.setVelocity(v_right)

            # Log (reduced frequency)
            if self.tick - last_log_tick >= 10:
                last_log_tick = self.tick
                print(
                    f"[t={self.tick}] pos=({self.state.x:.2f},{self.state.y:.2f}) "
                    f"theta={self.state.theta:.2f} "
                    f"target={target_name} dist={self.state.distance_to_goal:.2f} "
                    f"batt={self.state.battery_level:.1f} "
                    f"danger={self.state.obstacle_danger:.2f} "
                    f"Lobs={self.state.left_obstacle:.2f} "
                    f"Robs={self.state.right_obstacle:.2f} "
                    f"behavior={self.state.active_behavior} "
                    f"acts={acts} "
                    f"cmd=({v_left:.2f},{v_right:.2f})"
                )


if __name__ == "__main__":
    controller = IntelligentRobotController()
    controller.run_controller()

-------------------------------------------------------3333333333 Grid Code-------------------
# intelligent_robot_controller.py
# Version: Fuzzy behavior selection + Jitter suppression + A* + Improved obstacle avoidance & Low-battery priority charging

from controller import Supervisor
import math
import heapq

TIME_STEP = 64

START_X = -3.0
START_Y = -3.0

GOAL_POSITION = (1.0, 1.0)
CHARGING_STATION = (3.0, -3.0)

GOAL_REACHED_DIST = 0.15
WAYPOINT_REACHED_DIST = 0.12
CHARGING_REACHED_DIST = 0.15

MAP_MIN_X = -4.0
MAP_MAX_X = 4.0
MAP_MIN_Y = -4.0
MAP_MAX_Y = 4.0
GRID_RES = 0.1

GRID_WIDTH = int(round((MAP_MAX_X - MAP_MIN_X) / GRID_RES)) + 1
GRID_HEIGHT = int(round((MAP_MAX_Y - MAP_MIN_Y) / GRID_RES)) + 1


class RobotState:
    def __init__(self):
        self.x = START_X
        self.y = START_Y
        self.theta = 0.0

        self.battery_level = 100.0

        self.distance_to_goal = 0.0
        self.heading_error = 0.0

        self.obstacle_danger = 0.0
        self.left_obstacle = 0.0
        self.right_obstacle = 0.0

        # Behavior modes: "GOAL" / "AVOID" / "CHARGE"
        self.active_behavior = "GOAL"
        self.last_behavior = "GOAL"
        self.last_switch_tick = 0

        self.path = []
        self.path_index = 0
        self.current_high_level_target = "GOAL"

        # Stuck detection (expandable use)
        self.last_target_dist = None
        self.no_progress_ticks = 0

        self.mission_done = False


class IntelligentRobotController(Supervisor):
    def __init__(self):
        super().__init__()

        self.robot_node = self.getSelf()

        self.left_motor = self.getDevice("left wheel motor")
        self.right_motor = self.getDevice("right wheel motor")

        # Continuous rotation wheels
        self.left_motor.setPosition(float('inf'))
        self.right_motor.setPosition(float('inf'))
        self.left_motor.setVelocity(0.0)
        self.right_motor.setVelocity(0.0)

        # Distance sensors
        sensor_names = ["ps0", "ps1", "ps2", "ps3", "ps4", "ps5", "ps6", "ps7"]
        self.distance_sensors = []
        for name in sensor_names:
            s = self.getDevice(name)
            if s is not None:
                s.enable(TIME_STEP)
                self.distance_sensors.append(s)

        self.state = RobotState()
        self.tick = 0

        # Jitter suppression parameters
        self.behavior_cooldown = 20
        self.hysteresis_margin = 0.1

        # Static occupancy grid built from scene obstacles
        self.occupancy = self.build_static_occupancy()

        # Initial path planning towards goal
        self.plan_path_to_high_level_target("GOAL")

    # ===== Grid conversion =====
    def world_to_grid(self, x: float, y: float):
        gx = int(round((x - MAP_MIN_X) / GRID_RES))
        gy = int(round((y - MAP_MIN_Y) / GRID_RES))
        gx = max(0, min(GRID_WIDTH - 1, gx))
        gy = max(0, min(GRID_HEIGHT - 1, gy))
        return gx, gy

    def grid_to_world(self, gx: int, gy: int):
        x = MAP_MIN_X + gx * GRID_RES
        y = MAP_MIN_Y + gy * GRID_RES
        return x, y

    def build_static_occupancy(self):
        occ = [[0 for _ in range(GRID_WIDTH)] for _ in range(GRID_HEIGHT)]
    
        # Unified safety margin already applied in bounding box calculations
        # Each comment corresponds to one obstacle from your scene: x y z // size // rotation

        # 1) Roughly a vertical wall in upper area
        self.mark_obstacle_rect(
            occ,
            -0.644828, -0.344828,
            0.55576, 1.65576
        )

        # 2) Wall-like block
        self.mark_obstacle_rect(
            occ,
            0.822293, 1.122293,
            -0.832034, 0.267966
        )

        # 3) Vertical narrow wall
        self.mark_obstacle_rect(
            occ,
            -0.261627, 0.038373,
            -0.257186, 0.842814
        )

        # 4) Another upright wall
        self.mark_obstacle_rect(
            occ,
            -0.659825, -0.359825,
            0.61688, 1.71688
        )

        # 5) Bottom-left obstacle
        self.mark_obstacle_rect(
            occ,
            -2.8944, -2.5944,
            -2.88934, -1.78934
        )

        # 6) Upper right block
        self.mark_obstacle_rect(
            occ,
            0.759048, 1.059048,
            0.83008, 1.93008
        )

        # 7) Left-mid obstacle
        self.mark_obstacle_rect(
            occ,
            0.116012, 0.416012,
            -1.80274, -0.70274
        )

        # 8) Right-lower obstacle
        self.mark_obstacle_rect(
            occ,
            1.78989, 2.08989,
            -3.19774, -2.09774
        )

        # 9) Medium-left block
        self.mark_obstacle_rect(
            occ,
            -1.93915, -1.63915,
            -1.64284, -0.54284
        )

        # 10) Lower-left vertical wall
        self.mark_obstacle_rect(
            occ,
            -1.011625, -0.711625,
            -2.58397, -1.48397
        )

        # 11) Far left vertical long wall
        self.mark_obstacle_rect(
            occ,
            -3.36813, -3.06813,
            -0.315541, 0.784459
        )

        # ---- New obstacle A ----
        self.mark_obstacle_rect(
            occ,
            -0.274335, 0.025665,
            -1.405721, -0.305721
        )

        # ---- New obstacle B ----
        self.mark_obstacle_rect(
            occ,
            -2.02502, -1.72502,
            -2.85412, -1.75412
        )
    
        return occ

    def mark_obstacle_rect(self, occ, xmin, xmax, ymin, ymax):
        # Mark all grid cells covered by the rectangle as occupied
        gx_min, gy_min = self.world_to_grid(xmin, ymin)
        gx_max, gy_max = self.world_to_grid(xmax, ymax)
        for gy in range(min(gy_min, gy_max), max(gy_min, gy_max) + 1):
            for gx in range(min(gx_min, gx_max), max(gx_min, gx_max) + 1):
                occ[gy][gx] = 1

    # ===== A* pathfinding =====
    def astar(self, start_xy, goal_xy):
        sx, sy = start_xy
        gx, gy = goal_xy

        start_gx, start_gy = self.world_to_grid(sx, sy)
        goal_gx, goal_gy = self.world_to_grid(gx, gy)

        if self.occupancy[goal_gy][goal_gx] == 1:
            print(">>> [A*] Goal grid occupied, path may fail.")

        open_set = []
        heapq.heappush(open_set, (0.0, (start_gx, start_gy)))
        came_from = {}
        g_score = {(start_gx, start_gy): 0.0}

        def heuristic(ax, ay, bx, by):
            # Manhattan heuristic
            return abs(ax - bx) + abs(ay - by)

        closed = set()
        max_iter = GRID_WIDTH * GRID_HEIGHT * 4

        while open_set and max_iter > 0:
            max_iter -= 1
            _, (cx, cy) = heapq.heappop(open_set)
            if (cx, cy) in closed:
                continue
            closed.add((cx, cy))

            # Goal reached
            if cx == goal_gx and cy == goal_gy:
                path = []
                cur = (cx, cy)
                while cur in came_from:
                    path.append(cur)
                    cur = came_from[cur]
                path.append((start_gx, start_gy))
                path.reverse()
                wp = [self.grid_to_world(px, py) for (px, py) in path]
                return wp

            # Neighbor exploration (8-connected)
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx == 0 and dy == 0:
                        continue
                    nx = cx + dx
                    ny = cy + dy
                    if not (0 <= nx < GRID_WIDTH and 0 <= ny < GRID_HEIGHT):
                        continue
                    if self.occupancy[ny][nx] == 1:
                        continue

                    tentative_g = g_score[(cx, cy)] + math.hypot(dx, dy)
                    if (nx, ny) not in g_score or tentative_g < g_score[(nx, ny)]:
                        g_score[(nx, ny)] = tentative_g
                        f = tentative_g + heuristic(nx, ny, goal_gx, goal_gy)
                        heapq.heappush(open_set, (f, (nx, ny)))
                        came_from[(nx, ny)] = (cx, cy)

        print(">>> [A*] Failed to find path.")
        return []

    def plan_path_to_high_level_target(self, target_type: str):
        # Select target point: either charging station or goal
        if target_type == "CHARGE":
            target_xy = CHARGING_STATION
        else:
            target_xy = GOAL_POSITION

        start_xy = (self.state.x, self.state.y)
        path = self.astar(start_xy, target_xy)

        if not path:
            print(f">>> [A*] No path found to {target_type}, use direct point.")
            self.state.path = [target_xy]
            self.state.path_index = 0
        else:
            self.state.path = path
            self.state.path_index = 0
            print(f">>> [A*] Path to {target_type} planned with {len(path)} waypoints.")

        self.state.current_high_level_target = target_type
        self.state.last_target_dist = None
        self.state.no_progress_ticks = 0

    def get_current_path_target_point(self):
        # Safety fallback if path fails
        if self.state.current_high_level_target == "CHARGE":
            fallback = CHARGING_STATION
        else:
            fallback = GOAL_POSITION

        if not self.state.path:
            return fallback
        if self.state.path_index >= len(self.state.path):
            return fallback
        return self.state.path[self.state.path_index]

    # ===== Pose update =====
    def update_pose(self):
        trans = self.robot_node.getField("translation").getSFVec3f()
        rot = self.robot_node.getField("rotation").getSFRotation()

        self.state.x = trans[0]
        self.state.y = trans[1]

        axis_x, axis_y, axis_z, angle = rot
        self.state.theta = angle

        # Compute distance and heading error to current waypoint
        tx, ty = self.get_current_path_target_point()
        dx = tx - self.state.x
        dy = ty - self.state.y
        dist = math.hypot(dx, dy)
        self.state.distance_to_goal = dist

        target_theta = math.atan2(dy, dx)
        heading_err = target_theta - self.state.theta
        heading_err = (heading_err + math.pi) % (2.0 * math.pi) - math.pi
        self.state.heading_error = heading_err

        # Check if final goal reached
        gx, gy = GOAL_POSITION
        dist_final_goal = math.hypot(self.state.x - gx, self.state.y - gy)
        if self.state.current_high_level_target != "CHARGE" and dist_final_goal < GOAL_REACHED_DIST:
            if not self.state.mission_done:
                print(">>> [TASK] Final goal reached, mission complete.")
            self.state.mission_done = True

        # Waypoint progression
        if dist < WAYPOINT_REACHED_DIST and self.state.path:
            if self.state.path_index < len(self.state.path) - 1:
                self.state.path_index += 1

        # Distance to high-level target (used for potential stuck detection)
        if self.state.current_high_level_target == "CHARGE":
            tx2, ty2 = CHARGING_STATION
        else:
            tx2, ty2 = GOAL_POSITION
        dist_to_high_target = math.hypot(self.state.x - tx2, self.state.y - ty2)

        if self.state.last_target_dist is None:
            self.state.last_target_dist = dist_to_high_target
        else:
            if abs(dist_to_high_target - self.state.last_target_dist) < 0.005:
                self.state.no_progress_ticks += 1
            else:
                self.state.no_progress_ticks = 0
            self.state.last_target_dist = dist_to_high_target

        return self.state.current_high_level_target

    # ===== Sensor update =====
    def update_sensors(self):
        if not self.distance_sensors:
            return

        values = [s.getValue() for s in self.distance_sensors]
        max_val = max(values)

        # Normalize danger intensity
        baseline = 60.0
        max_range = 80.0
        danger_raw = (max_val - baseline) / max_range
        danger = max(0.0, min(1.0, danger_raw))
        self.state.obstacle_danger = danger

        # Sum left and right sensor groups
        if len(values) == 8:
            left_sum = sum(values[0:4])
            right_sum = sum(values[4:8])
        else:
            mid = len(values) // 2
            left_sum = sum(values[:mid])
            right_sum = sum(values[mid:])

        norm = 400.0
        self.state.left_obstacle = min(1.0, left_sum / norm)
        self.state.right_obstacle = min(1.0, right_sum / norm)

    # ===== Battery update =====
    def update_battery(self, moving: bool):
        if self.state.mission_done:
            return

        # Consumption rate
        if moving:
            self.state.battery_level -= 0.02
        else:
            self.state.battery_level -= 0.005

        if self.state.battery_level < 0.0:
            self.state.battery_level = 0.0
        if self.state.battery_level > 100.0:
            self.state.battery_level = 100.0

        # Charging logic
        if self.state.active_behavior == "CHARGE":
            dist_to_charge = math.hypot(
                self.state.x - CHARGING_STATION[0],
                self.state.y - CHARGING_STATION[1]
            )
            if dist_to_charge < CHARGING_REACHED_DIST:
                self.state.battery_level += 0.5
                if self.state.battery_level >= 100.0:
                    self.state.battery_level = 100.0
                    print(">>> [BAT] Fully charged at station.")

    # ===== Fuzzy membership functions =====
    def fuzzy_low_battery(self, batt: float) -> float:
        if batt >= 60.0:
            return 0.0
        if batt <= 20.0:
            return 1.0
        return (60.0 - batt) / 40.0

    def fuzzy_obstacle_near(self, danger: float) -> float:
        return max(0.0, min(1.0, danger))

    def fuzzy_far_from_goal(self, dist: float) -> float:
        if dist <= 0.1:
            return 0.0
        if dist >= 1.0:
            return 1.0
        return (dist - 0.1) / 0.9

    # ===== Behavior selection (low battery prioritizes CHARGE) =====
    def select_behavior(self):
        batt = self.state.battery_level
        danger = self.state.obstacle_danger
        dist = self.state.distance_to_goal

        mu_low_batt = self.fuzzy_low_battery(batt)
        mu_obs = self.fuzzy_obstacle_near(danger)
        mu_far = self.fuzzy_far_from_goal(dist)

        act_charge = mu_low_batt
        act_avoid = mu_obs
        act_goal = (1.0 - mu_low_batt) * max(0.0, 1.0 - mu_obs) * mu_far

        activations = {
            "CHARGE": act_charge,
            "AVOID": act_avoid,
            "GOAL": act_goal
        }

        # Low-battery priority: force charging when below 25% or fuzzy low-battery > 0.8
        if batt < 25.0 or mu_low_batt > 0.8:
            if self.state.current_high_level_target != "CHARGE":
                self.plan_path_to_high_level_target("CHARGE")
            self.state.active_behavior = "CHARGE"
            return activations

        best_behavior = max(activations, key=activations.get)
        best_act = activations[best_behavior]

        current = self.state.active_behavior
        current_act = activations[current]
        switched = False

        # Cooldown-based hysteresis
        if (self.tick - self.state.last_switch_tick) < self.behavior_cooldown:
            if best_act > current_act + self.hysteresis_margin:
                self.state.last_behavior = current
                self.state.active_behavior = best_behavior
                self.state.last_switch_tick = self.tick
                switched = True
        else:
            if current_act + self.hysteresis_margin < best_act:
                self.state.last_behavior = current
                self.state.active_behavior = best_behavior
                self.state.last_switch_tick = self.tick
                switched = True

        if switched:
            if self.state.active_behavior == "CHARGE" and self.state.current_high_level_target != "CHARGE":
                self.plan_path_to_high_level_target("CHARGE")
            elif self.state.active_behavior == "GOAL" and self.state.current_high_level_target != "GOAL":
                self.plan_path_to_high_level_target("GOAL")

        return activations

    # ===== Control command (improved: when both sides very close, reverse straight out) =====
    def compute_command(self):
        if self.state.mission_done or self.state.battery_level <= 0.0:
            return 0.0, 0.0

        d = self.state.distance_to_goal
        e = self.state.heading_error
        danger = self.state.obstacle_danger
        left_o = self.state.left_obstacle
        right_o = self.state.right_obstacle

        max_speed = 6.28
        behavior = self.state.active_behavior

        # Charging station stopping
        if behavior == "CHARGE":
            dist_to_charge = math.hypot(
                self.state.x - CHARGING_STATION[0],
                self.state.y - CHARGING_STATION[1]
            )
            if dist_to_charge < CHARGING_REACHED_DIST:
                return 0.0, 0.0

        # High danger + both sides extremely close → considered trapped → reverse straight
        if danger > 0.9 and left_o > 0.9 and right_o > 0.9:
            v = -2.0
            w = 0.0
        else:
            if behavior == "AVOID":
                if danger > 0.6:
                    turn_bias = 3.0 if left_o > right_o else -3.0
                    v = -2.0   # slightly smaller to avoid excessive spinning
                    w = turn_bias
                else:
                    v = 1.5
                    w = 4.0 * (right_o - left_o)
            elif behavior == "CHARGE":
                v = 3.0 * min(d, 1.0)
                w = 3.0 * e
            else:  # GOAL
                if danger > 0.5:
                    v = 2.0
                    w = 3.0 * (right_o - left_o)
                else:
                    v = 4.0 * min(d, 1.0)
                    w = 3.0 * e

        # Differential drive conversion
        v_left = v - w
        v_right = v + w

        # Bound wheel speeds
        v_left = max(-max_speed, min(max_speed, v_left))
        v_right = max(-max_speed, min(max_speed, v_right))

        return v_left, v_right

    # ===== Main loop =====
    def run_controller(self):
        last_log_tick = -999

        while self.step(TIME_STEP) != -1:
            self.tick += 1

            if self.state.battery_level <= 0.0:
                print(">>> [BAT] Battery empty, stop.")
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            if self.state.mission_done:
                self.left_motor.setVelocity(0.0)
                self.right_motor.setVelocity(0.0)
                continue

            target_name = self.update_pose()
            self.update_sensors()

            acts = self.select_behavior()

            v_left, v_right = self.compute_command()
            moving = (abs(v_left) > 0.05 or abs(v_right) > 0.05)

            self.update_battery(moving)

            self.left_motor.setVelocity(v_left)
            self.right_motor.setVelocity(v_right)

            # Periodic logging
            if self.tick - last_log_tick >= 20:
                last_log_tick = self.tick
                print(
                    f"[t={self.tick}] pos=({self.state.x:.2f},{self.state.y:.2f}) "
                    f"theta={self.state.theta:.2f} "
                    f"HL_target={self.state.current_high_level_target} "
                    f"dist={self.state.distance_to_goal:.2f} "
                    f"batt={self.state.battery_level:.1f} "
                    f"danger={self.state.obstacle_danger:.2f} "
                    f"Lobs={self.state.left_obstacle:.2f} "
                    f"Robs={self.state.right_obstacle:.2f} "
                    f"behavior={self.state.active_behavior} "
                    f"acts={acts} "
                    f"wp_idx={self.state.path_index}/{len(self.state.path)} "
                    f"cmd=({v_left:.2f},{v_right:.2f})"
                )


if __name__ == "__main__":
    controller = IntelligentRobotController()
    controller.run_controller()



